name: Talos Conformance (PR)
on:
  pull_request: {}
jobs:
  setup-and-test:
    runs-on: ubuntu-24.04
    permissions:
      id-token: write
      contents: read
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        cilium:
          # renovate: datasource=github-releases depName=cilium/cilium
          - '1.17.5'
        talos:
          # renovate: datasource=github-releases depName=siderolabs/talos
          - 'v1.10.5'
        config:
          - name: 'Cilium-Reference-Config'
            kube-proxy: false
            kube-proxy-replacement: "true"
            socketlb: true
            bpf-masquerade: true
            bpf-hostlegacyrouting: true
            ipam-mode: 'kubernetes'
            ipv4: true
            ipv6: false
            encryption-enabled: false
            encryption-type: ""
            tunnel-mode: vxlan
            nodeport: false
            ingress-controller: false
    steps:
      - name: Checkout
        uses: actions/checkout@09d2acae674a48949e3602304ab46fd20ae0c42f
        with:
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Configure AWS credentials from shared services account
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::478566851380:role/TalosConformanceCI
          aws-region: us-east-2

      - uses: hashicorp/setup-terraform@v3

      - name: GH Runner Public IP
        id: public_ip
        run: |
          # Get the public IP of the runner
          RUNNER_PUBLIC_IP=$(curl -sSf https://api.ipify.org)
          echo "Runner public IP: $RUNNER_PUBLIC_IP"
          echo "RUNNER_PUBLIC_IP=$RUNNER_PUBLIC_IP" >> "$GITHUB_OUTPUT"

      - name: GH Runner Private IP
        id: private_ip
        run: |
          # Get the private IP of the runner
          # Detect first non-loopback IPv4 address
          RUNNER_PRIVATE_IP=$(ip -4 -o addr show scope global | awk '{print $4}' | cut -d/ -f1 | head -n1)
          echo "Runner private IP: $RUNNER_PRIVATE_IP"
          echo "RUNNER_PRIVATE_IP=$RUNNER_PRIVATE_IP" >> "$GITHUB_OUTPUT"

      - name: Create Talos Cluster
        run: |
          cd test/conformance
          ./create-ci-env.sh \
            --kube-proxy ${{ matrix.config.kube-proxy}} \
            --talos-version ${{ matrix.talos }} \
            --test $(echo "${{ matrix.config.name }}" | sed 's/ /_/g') \
            --run-id ${{ github.run_id }} \
            --run-no ${{ github.run_number }} \
            --cilium-version ${{ matrix.cilium }} \
            --owner "isovalent/terraform-aws-talos"
          make apply

      - name: Install latest Cilium CLI
        run: |
          CILIUM_CLI_VERSION=$(curl -sSf --retry 5 --retry-delay 3 --retry-connrefused https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
          CLI_ARCH="$(arch | sed 's/x86_64/amd64/; s/aarch64/arm64/')"
          curl -sSLf --retry 5 --retry-delay 3 --retry-connrefused --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
          sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum
          sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin
          rm cilium-linux-${CLI_ARCH}.tar.gz*

      - name: Install Cilium
        run: |
          cd test/conformance
          # Wait until the apiserver LB is ready
          timeout 120 bash -c "until curl -sS https://$(terraform output -raw lb_dns_name):443 -k -m 3; do sleep 1 && echo 'waiting for apiserver'; done"
          if [ $? -ne 0 ]; then
            echo "API Server LB failed to become available."
            exit 1
          fi
          # Wait another few seconds as we have multiple LB backend endpoints
          sleep 10
          export $(make print-kubeconfig)
          kubectl create -n kube-system secret generic cilium-ipsec-keys \
            --from-literal=keys="3 rfc4106(gcm(aes)) $(echo $(dd if=/dev/urandom count=20 bs=1 2> /dev/null | xxd -p -c 64)) 128"
          kubectl create -n kube-system -f ipmasq-config.yaml
          cilium install --version="v${{ matrix.cilium }}" \
            --values=values.yaml \
            --set ipv4.enabled=${{ matrix.config.ipv4 }} \
            --set ipv6.enabled=${{ matrix.config.ipv6 }} \
            --set bpf.masquerade=${{ matrix.config.bpf-masquerade }} \
            --set bpf.hostLegacyRouting=${{ matrix.config.bpf-hostlegacyrouting }} \
            --set kubeProxyReplacement=${{ matrix.config.kube-proxy-replacement }} \
            --set socketLB.enabled=${{ matrix.config.socketlb }} \
            --set ipam.mode=${{ matrix.config.ipam-mode }} \
            --set ingressController.enabled=${{ matrix.config.ingress-controller }} \
            --set encryption.enabled=${{ matrix.config.encryption-enabled }} \
            --set encryption.type=${{ matrix.config.encryption-type }} \
            --set tunnelProtocol=${{ matrix.config.tunnel-mode }} \
            --set nodePort.enabled=${{ matrix.config.nodeport }}
          cilium status --wait

      - id: run-tests
        name: Run E2E Connectivity Tests
        run: |
          cd test/conformance
          export $(make print-kubeconfig)
          ./wait
          # Cilium Connectivity tests namespace
          TEST_NAMESPACE="cilium-test"
          # All Cilium Connectivity tests namespaces
          NAMESPACES=("${TEST_NAMESPACE}" "${TEST_NAMESPACE}-1")

          # Identify the namespace where Cilium is installed
          CILIUM_NAMESPACE=$(kubectl get ds -A -l k8s-app=cilium -o jsonpath='{.items[0].metadata.namespace}')

          # NS precreation is required because of https://www.talos.dev/v1.5/kubernetes-guides/configuration/pod-security/
          for ns in "${NAMESPACES[@]}"; do
            kubectl create ns "${ns}"
            kubectl label ns "${ns}" pod-security.kubernetes.io/enforce=privileged
            kubectl label ns "${ns}" pod-security.kubernetes.io/warn=privileged
          done

          # Run the connectivity tests.
          cilium connectivity test \
            --namespace "${CILIUM_NAMESPACE}" \
            --test-namespace "${TEST_NAMESPACE}" \
            --hubble=false \
            --flow-validation=disabled \
            --test "!no-policies,!allow-all-except-world"
          # cilium connectivity test --collect-sysdump-on-failure

      - name: Fetch artifacts
        if: ${{ !success() && steps.run-tests.outcome != 'skipped' }}
        shell: bash
        run: |
          cd test/conformance
          export $(make print-kubeconfig)
          kubectl get svc -o wide -A
          kubectl get pods --all-namespaces -o wide
          cilium status
          mkdir -p cilium-sysdumps
          cilium sysdump --output-filename cilium-sysdump-${{ github.run_id }}-${{ github.run_number }}

      - name: Upload artifacts
        if: ${{ !success() }}
        uses: actions/upload-artifact@834a144ee995460fba8ed112a2fc961b36a5ec5a # v4.3.6
        with:
          name: cilium-sysdumps-${{ github.run_id }}-${{ github.run_number }}
          path: ./test/conformance/cilium-sysdump-*.zip

      - name: Cleanup
        if: always()
        run: |
          cd test/conformance
          make destroy
